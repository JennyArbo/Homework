{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jenniferarbuszewski/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Suspendisse', 'dignissim', 'pretium', 'lectus', ',', 'dignissim', 'molestie', 'lacus', 'viverra', 'eu', '.', 'Sed', 'venenatis', 'mauris', 'vel', 'tellus', 'ornare', 'tempus', '.', 'Aenean', 'in', 'laoreet', 'eros', '.', 'Duis', 'feugiat', ',', 'elit', 'non', 'maximus', 'auctor', ',', 'sapien', 'ex', 'vehicula', 'nulla', ',', 'sit', 'amet', 'cursus', 'dui', 'orci', 'ut', 'tellus', '.', 'Duis', 'cursus', 'volutpat', 'convallis', '.', 'Maecenas', 'posuere', 'tortor', 'enim', '.', 'Maecenas', 'vulputate', 'mauris', 'placerat', ',', 'ultrices', 'odio', 'in', ',', 'condimentum', 'arcu', '.', 'Cras', 'sollicitudin', 'mauris', 'at', 'justo', 'tristique', ',', 'at', 'condimentum', 'ante', 'ornare', '.', 'Vivamus', 'cursus', 'sapien', 'et', 'sapien', 'mattis', 'tristique', '.', 'Duis', 'et', 'tincidunt', 'ipsum', '.', 'Integer', 'interdum', 'vulputate', 'lorem', ',', 'sed', 'hendrerit', 'felis', 'pulvinar', 'ut', '.', 'Vivamus', 'non', 'lectus', 'bibendum', 'imperdiet', 'pretium', 'vel', 'in', 'libero', '.', 'Aliquam', 'semper', 'tincidunt', 'turpis', 'et', 'feugiat', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#https://www.lipsum.com/feed/html\n",
    "text='''Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
    "Suspendisse dignissim pretium lectus, \n",
    "dignissim molestie lacus viverra eu. \n",
    "Sed venenatis mauris vel tellus ornare tempus. \n",
    "Aenean in laoreet eros. Duis feugiat, elit non maximus\n",
    "auctor, sapien ex vehicula nulla, sit amet cursus dui \n",
    "orci ut tellus. Duis cursus volutpat convallis. \n",
    "Maecenas posuere tortor enim. Maecenas vulputate \n",
    "mauris placerat, ultrices odio in, condimentum arcu. \n",
    "Cras sollicitudin mauris at justo tristique, at \n",
    "condimentum ante ornare. Vivamus cursus sapien et \n",
    "sapien mattis tristique. Duis et tincidunt ipsum. \n",
    "Integer interdum vulputate lorem, sed hendrerit \n",
    "felis pulvinar ut. Vivamus non lectus bibendum \n",
    "imperdiet pretium vel in libero. Aliquam semper \n",
    "tincidunt turpis et feugiat.'''\n",
    "print(word_tokenize(text))\n",
    "#keras has a tokenzier\n",
    "#boundary of words can be complicated, but in english this is not as hard as some other langauges\n",
    "#handling symbols can also be hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gutenberg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/jenniferarbuszewski/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiw = nltk.corpus.gutenberg.words('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Alice', \"'\", 's', 'Adventures', 'in', ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words: [\"weren't\", \"mustn't\", 'no', 'did', 'o', 'after', 'while', 'than', 'can', 'so']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jenniferarbuszewski/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# stop words are common words that have low information value in text\n",
    "#we generally get rid of stop words\n",
    "nltk.download('stopwords')\n",
    "sw = set(nltk.corpus.stopwords.words('english'))\n",
    "print(\"Stop words: \" + str(list(sw)[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']'], ['CHAPTER', 'I', '.'], ['Down', 'the', 'Rabbit', '-', 'Hole'], ['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'\", 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'or', 'conversation', \"?'\"], ['So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', '),', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy', '-', 'chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', ',', 'when', 'suddenly', 'a', 'White', 'Rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her', '.'], ['There', 'was', 'nothing', 'so', 'VERY', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'Alice', 'think', 'it', 'so', 'VERY', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'Rabbit', 'say', 'to', 'itself', ',', \"'\", 'Oh', 'dear', '!'], ['Oh', 'dear', '!'], ['I', 'shall', 'be', 'late', \"!'\"], ['(', 'when', 'she', 'thought', 'it', 'over', 'afterwards', ',', 'it', 'occurred', 'to', 'her', 'that', 'she', 'ought', 'to', 'have', 'wondered', 'at', 'this', ',', 'but', 'at', 'the', 'time', 'it', 'all', 'seemed', 'quite', 'natural', ');', 'but', 'when', 'the', 'Rabbit', 'actually', 'TOOK', 'A', 'WATCH', 'OUT', 'OF', 'ITS', 'WAISTCOAT', '-', 'POCKET', ',', 'and', 'looked', 'at', 'it', ',', 'and', 'then', 'hurried', 'on', ',', 'Alice', 'started', 'to', 'her', 'feet', ',', 'for', 'it', 'flashed', 'across', 'her', 'mind', 'that', 'she', 'had', 'never', 'before', 'seen', 'a', 'rabbit', 'with', 'either', 'a', 'waistcoat', '-', 'pocket', ',', 'or', 'a', 'watch', 'to', 'take', 'out', 'of', 'it', ',', 'and', 'burning', 'with', 'curiosity', ',', 'she', 'ran', 'across', 'the', 'field', 'after', 'it', ',', 'and', 'fortunately', 'was', 'just', 'in', 'time', 'to', 'see', 'it', 'pop', 'down', 'a', 'large', 'rabbit', '-', 'hole', 'under', 'the', 'hedge', '.'], ['In', 'another', 'moment', 'down', 'went', 'Alice', 'after', 'it', ',', 'never', 'once', 'considering', 'how', 'in', 'the', 'world', 'she', 'was', 'to', 'get', 'out', 'again', '.']]\n"
     ]
    }
   ],
   "source": [
    "#stop words are all lowercase. You want to do this too\n",
    "#nltk.download('punkt')\n",
    "text_sentences = nltk.corpus.gutenberg.sents(\"carroll-alice.txt\")[:10]\n",
    "print(text_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'\", 'Adventures', 'Wonderland', 'Lewis', 'Carroll', '1865', ']']\n",
      "['CHAPTER', '.']\n",
      "['Rabbit', '-', 'Hole']\n",
      "['Alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', ',', 'nothing', ':', 'twice', 'peeped', 'book', 'sister', 'reading', ',', 'pictures', 'conversations', ',', \"'\", 'use', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'conversation', \"?'\"]\n",
      "['considering', 'mind', '(', 'well', 'could', ',', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', '),', 'whether', 'pleasure', 'making', 'daisy', '-', 'chain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', ',', 'suddenly', 'White', 'Rabbit', 'pink', 'eyes', 'ran', 'close', '.']\n",
      "['nothing', 'remarkable', ';', 'Alice', 'think', 'much', 'way', 'hear', 'Rabbit', 'say', ',', \"'\", 'Oh', 'dear', '!']\n",
      "['Oh', 'dear', '!']\n",
      "['shall', 'late', \"!'\"]\n",
      "['(', 'thought', 'afterwards', ',', 'occurred', 'ought', 'wondered', ',', 'time', 'seemed', 'quite', 'natural', ');', 'Rabbit', 'actually', 'TOOK', 'WATCH', 'WAISTCOAT', '-', 'POCKET', ',', 'looked', ',', 'hurried', ',', 'Alice', 'started', 'feet', ',', 'flashed', 'across', 'mind', 'never', 'seen', 'rabbit', 'either', 'waistcoat', '-', 'pocket', ',', 'watch', 'take', ',', 'burning', 'curiosity', ',', 'ran', 'across', 'field', ',', 'fortunately', 'time', 'see', 'pop', 'large', 'rabbit', '-', 'hole', 'hedge', '.']\n",
      "['another', 'moment', 'went', 'Alice', ',', 'never', 'considering', 'world', 'get', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['another',\n",
       " 'moment',\n",
       " 'went',\n",
       " 'Alice',\n",
       " ',',\n",
       " 'never',\n",
       " 'considering',\n",
       " 'world',\n",
       " 'get',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in text_sentences:\n",
    "    filtered_list = [w for w in sentence if w.lower() not in sw]\n",
    "    print(filtered_list)\n",
    "filtered_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take one or two characters that should be eliminated, and write a list comprehension to remove them from the filtered_list\n",
    "#you can use punkt to do that or you can do it \"manually\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worrier'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming - finding root words\n",
    "# overstemming - words are over truncated car vs caring \n",
    "#understemming (false negative) - \"alumnus\" -> \"alumnu\"\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language = \"english\")\n",
    "word = 'worrier'\n",
    "stemmer.stem(word)\n",
    "#fun fact: Google adopted word stemming in 2003. Prior to that, searching \"fish\"\n",
    "# would not have given results for \"fishing\" or \"fishes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jenniferarbuszewski/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worrier\n"
     ]
    }
   ],
   "source": [
    "#lemmatization - finding the form of a word thats related in the dictionary. \n",
    "#the process for calculating lemmas is more complicated than stemming\n",
    "#lemmatization considers the context and converts the word to a \"meaningful base form\" (a lemma)\n",
    "#a word can have multiple lemmas\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('worrier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jenniferarbuszewski/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.006, 'neu': 0.983, 'pos': 0.012, 'compound': 0.4019}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'Etymology and naming\\nThe origin of the English word \\'cat\\', Old English catt, is thought to be the Late Latin word cattus, which was first used at the beginning of the 6th century.[20] It was suggested that the word \\'cattus\\' is derived from an Egyptian precursor of Coptic ϣⲁⲩ šau, \"tomcat\", or its feminine form suffixed with -t.[21] The Late Latin word may be derived from another Afro-Asiatic[22] or Nilo-Saharan language. The Nubian word kaddîska \"wildcat\" and Nobiin kadīs are possible sources or cognates.[23] The Nubian word may be a loan from Arabic قَطّ\\u200e qaṭṭ ~ قِطّ qiṭṭ. It is \"equally likely that the forms might derive from an ancient Germanic word, imported into Latin and thence to Greek and to Syriac and Arabic\".[24] The word may be derived from Germanic and Northern European languages, and ultimately be borrowed from Uralic, cf. Northern Sami gáđfi, \"female stoat\", and Hungarian hölgy, \"stoat\"; from Proto-Uralic *käďwä, \"female (of a furred animal)\".[25]\\n\\nThe English puss, extended as pussy and pussycat, is attested from the 16th century and may have been introduced from Dutch poes or from Low German puuskatte, related to Swedish kattepus, or Norwegian pus, pusekatt. Similar forms exist in Lithuanian puižė and Irish puisín or puiscín. The etymology of this word is unknown, but it may have simply arisen from a sound used to attract a cat.[26][27]\\n\\nA male cat is called a tom or tomcat[28] (or a gib,[29] if neutered). An unspayed female is called a queen,[30] especially in a cat-breeding context. A juvenile cat is referred to as a kitten. In Early Modern English, the word kitten was interchangeable with the now-obsolete word catling.[31] A group of cats can be referred to as a clowder or a glaring.[32]\\n',\n",
       "  'compound': 0.4019,\n",
       "  'positive': 0.012,\n",
       "  'negative': 0.006,\n",
       "  'neutral': 0.983}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Etymology and naming\n",
    "The origin of the English word 'cat', Old English catt, is thought to be the Late Latin word cattus, which was first used at the beginning of the 6th century.[20] It was suggested that the word 'cattus' is derived from an Egyptian precursor of Coptic ϣⲁⲩ šau, \"tomcat\", or its feminine form suffixed with -t.[21] The Late Latin word may be derived from another Afro-Asiatic[22] or Nilo-Saharan language. The Nubian word kaddîska \"wildcat\" and Nobiin kadīs are possible sources or cognates.[23] The Nubian word may be a loan from Arabic قَطّ‎ qaṭṭ ~ قِطّ qiṭṭ. It is \"equally likely that the forms might derive from an ancient Germanic word, imported into Latin and thence to Greek and to Syriac and Arabic\".[24] The word may be derived from Germanic and Northern European languages, and ultimately be borrowed from Uralic, cf. Northern Sami gáđfi, \"female stoat\", and Hungarian hölgy, \"stoat\"; from Proto-Uralic *käďwä, \"female (of a furred animal)\".[25]\n",
    "\n",
    "The English puss, extended as pussy and pussycat, is attested from the 16th century and may have been introduced from Dutch poes or from Low German puuskatte, related to Swedish kattepus, or Norwegian pus, pusekatt. Similar forms exist in Lithuanian puižė and Irish puisín or puiscín. The etymology of this word is unknown, but it may have simply arisen from a sound used to attract a cat.[26][27]\n",
    "\n",
    "A male cat is called a tom or tomcat[28] (or a gib,[29] if neutered). An unspayed female is called a queen,[30] especially in a cat-breeding context. A juvenile cat is referred to as a kitten. In Early Modern English, the word kitten was interchangeable with the now-obsolete word catling.[31] A group of cats can be referred to as a clowder or a glaring.[32]\n",
    "'''\n",
    "sentiments=[]\n",
    "sentiment = analyzer.polarity_scores(text)\n",
    "print(sentiment)\n",
    "compound = sentiment[\"compound\"]\n",
    "pos = sentiment[\"pos\"]\n",
    "neu = sentiment[\"neu\"]\n",
    "neg = sentiment[\"neg\"]\n",
    "sentiments.append({\n",
    "            \"text\":text,\n",
    "            \"compound\":compound,\n",
    "            \"positive\":pos,\n",
    "            \"negative\":neg,\n",
    "            \"neutral\":neu\n",
    "})\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Class Exercise Begins Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Take the result of the following line of code (but use whatever available text you want) and write a function to concatenate the data back into sentences, with one readable sentence in each list.sentences = nltk.corpus.gutenberg.sents(\"carroll-alice.txt\")[:10]\n",
    "\n",
    "\n",
    "### 2. Create a function that accepts a list of values. Filter out all values that are numeric and return the new list.\n",
    "#### Input:\n",
    "#### [1,2,'a','b',7.6]\n",
    "#### output: [‘a’,’b’]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']'], ['CHAPTER', 'I', '.'], ['Down', 'the', 'Rabbit', '-', 'Hole'], ['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'\", 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'or', 'conversation', \"?'\"], ['So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', '),', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy', '-', 'chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', ',', 'when', 'suddenly', 'a', 'White', 'Rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her', '.'], ['There', 'was', 'nothing', 'so', 'VERY', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'Alice', 'think', 'it', 'so', 'VERY', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'Rabbit', 'say', 'to', 'itself', ',', \"'\", 'Oh', 'dear', '!'], ['Oh', 'dear', '!'], ['I', 'shall', 'be', 'late', \"!'\"], ['(', 'when', 'she', 'thought', 'it', 'over', 'afterwards', ',', 'it', 'occurred', 'to', 'her', 'that', 'she', 'ought', 'to', 'have', 'wondered', 'at', 'this', ',', 'but', 'at', 'the', 'time', 'it', 'all', 'seemed', 'quite', 'natural', ');', 'but', 'when', 'the', 'Rabbit', 'actually', 'TOOK', 'A', 'WATCH', 'OUT', 'OF', 'ITS', 'WAISTCOAT', '-', 'POCKET', ',', 'and', 'looked', 'at', 'it', ',', 'and', 'then', 'hurried', 'on', ',', 'Alice', 'started', 'to', 'her', 'feet', ',', 'for', 'it', 'flashed', 'across', 'her', 'mind', 'that', 'she', 'had', 'never', 'before', 'seen', 'a', 'rabbit', 'with', 'either', 'a', 'waistcoat', '-', 'pocket', ',', 'or', 'a', 'watch', 'to', 'take', 'out', 'of', 'it', ',', 'and', 'burning', 'with', 'curiosity', ',', 'she', 'ran', 'across', 'the', 'field', 'after', 'it', ',', 'and', 'fortunately', 'was', 'just', 'in', 'time', 'to', 'see', 'it', 'pop', 'down', 'a', 'large', 'rabbit', '-', 'hole', 'under', 'the', 'hedge', '.'], ['In', 'another', 'moment', 'down', 'went', 'Alice', 'after', 'it', ',', 'never', 'once', 'considering', 'how', 'in', 'the', 'world', 'she', 'was', 'to', 'get', 'out', 'again', '.']]\n"
     ]
    }
   ],
   "source": [
    "#starter code from question:\n",
    "\n",
    "sentences = nltk.corpus.gutenberg.sents(\"carroll-alice.txt\")[:10]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ]\n",
      "CHAPTER I .\n",
      "Down the Rabbit - Hole\n",
      "Alice was beginning to get very tired of sitting by her sister on the bank , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ' and what is the use of a book ,' thought Alice ' without pictures or conversation ?'\n",
      "So she was considering in her own mind ( as well as she could , for the hot day made her feel very sleepy and stupid ), whether the pleasure of making a daisy - chain would be worth the trouble of getting up and picking the daisies , when suddenly a White Rabbit with pink eyes ran close by her .\n",
      "There was nothing so VERY remarkable in that ; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself , ' Oh dear !\n",
      "Oh dear !\n",
      "I shall be late !'\n",
      "( when she thought it over afterwards , it occurred to her that she ought to have wondered at this , but at the time it all seemed quite natural ); but when the Rabbit actually TOOK A WATCH OUT OF ITS WAISTCOAT - POCKET , and looked at it , and then hurried on , Alice started to her feet , for it flashed across her mind that she had never before seen a rabbit with either a waistcoat - pocket , or a watch to take out of it , and burning with curiosity , she ran across the field after it , and fortunately was just in time to see it pop down a large rabbit - hole under the hedge .\n",
      "In another moment down went Alice after it , never once considering how in the world she was to get out again .\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def make_sentence(text):\n",
    "    paragraph_list = []\n",
    "    for sentence in text:\n",
    "        sentence_list = []\n",
    "        x=' '.join(sentence)\n",
    "        print(x)\n",
    "        #for word in sentence:\n",
    "           # sentence_list = sentence_list.join([' ' + a ])\n",
    "           # return sentence_list\n",
    "\n",
    "\n",
    "#>>> import nltk\n",
    "#>>> import string\n",
    "#>>> nltk.word_tokenize(\"I've found a medicine for my disease.\")\n",
    "#['I', \"'ve\", 'found', 'a', 'medicine', 'for', 'my', 'disease', '.']\n",
    "#>>> tokens = nltk.word_tokenize(\"I've found a medicine for my disease.\")\n",
    "#>>> \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()\n",
    "#\"I've found a medicine for my disease.\"\n",
    "        \n",
    "   # \"\"\"\n",
    "    #Untokenizing a text undoes the tokenizing operation, restoring\n",
    "    #punctuation and spaces to the places that people expect them to be.\n",
    "    #Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
    "    #except for line breaks.\n",
    "    #\"\"\"\n",
    "    #text = ' '.join(words)\n",
    "    #step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
    "    #step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
    "    #step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
    "    #step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
    "    #step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
    "      #   \"can not\", \"cannot\")\n",
    "    #step6 = step5.replace(\" ` \", \" '\")\n",
    "    #return step6.strip()\n",
    "\n",
    " #tokenized = ['I', \"'ve\", 'found', 'a', 'medicine', 'for', 'my','disease', '.']\n",
    " #untokenize(tokenized)\n",
    " #\"I've found a medicine for my disease.\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice 's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "CHAPTER I.\n",
      "Down the Rabbit-Hole\n",
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\n",
      "There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\n",
      "Oh dear!\n",
      "I shall be late!'\n",
      "(when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually TOOK A WATCH OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\n",
      "In another moment down went Alice after it, never once considering how in the world she was to get out again.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Trying to handle the weird spacing arround punctuation\n",
    "def make_sentence_spaces(text):\n",
    "    #This function will untokenize the text tokenized above. Trying to deal with some spacing issues.\n",
    "    #setting up an empty string to store untokenized sentences in\n",
    "    s= ''\n",
    "    for sentence in text:\n",
    "        #Setting up a boolean so we can define where there should/should not be spaces\n",
    "        after_space = True\n",
    "        \n",
    "        #Identifying the index for each word in the sentence\n",
    "        for index, word in enumerate(sentence):\n",
    "            #Setting before and after space the same so I don't end up with double spaces; if word before\n",
    "            #shouldn't have a space after it, essentially \"telling\" that to the next word\n",
    "            before_space = after_space\n",
    "            #Assumption is there should always be a space after each element but special cases given belo\n",
    "            #to override where appropriate\n",
    "            after_space = True\n",
    "            #If the index = 0, this is the start of a new chapter/paragraph/etc and should not have a space before\n",
    "            #Giving special cases for punctuation below\n",
    "            if index == 0:\n",
    "                before_space = False\n",
    "            if word[0] in \"!,.?:;-)]\":\n",
    "                before_space = False\n",
    "            if word in \"([-'\\\"\":\n",
    "                after_space = False\n",
    "            \n",
    "            #Adding one word at a time to recreate each sentence\n",
    "            if before_space:\n",
    "                s = s + ' '\n",
    "            s = s + word\n",
    "        #Combining all of the sentences and putting each new sentence on a new line\n",
    "        s = s + '\\n'\n",
    "    return(s)\n",
    "        \n",
    "print(make_sentence_spaces(sentences))\n",
    "\n",
    "#Note: this still is not great but it is more readable than previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n",
      "['d', 't', 'c']\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "This is not a list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-883c6c76abe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-883c6c76abe5>\u001b[0m in \u001b[0;36malpha_only\u001b[0;34m(check_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0malpha_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This is not a list.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0malpha_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: This is not a list."
     ]
    }
   ],
   "source": [
    "def alpha_only(check_list):\n",
    "    if not isinstance(check_list, list):\n",
    "            raise Exception('This is not a list.')\n",
    "    alpha_list = []\n",
    "    for a in check_list:\n",
    "            if not isinstance(a, int) and not isinstance(a, float):\n",
    "                #Checks to make sure if string and does not take numeric string values\n",
    "                if isinstance(a, str) and a.isalpha():\n",
    "                     alpha_list.append(a)\n",
    "    #print('Output:', alpha_list)\n",
    "    return (alpha_list)\n",
    "test = ['a', 1, 3, 'b', 3, 4]\n",
    "test2 = ['d', '1', 2, 't', 'c']\n",
    "test3 = {1:'a', 2:'b'}\n",
    "\n",
    "print(alpha_only(test))\n",
    "print(alpha_only(test2))\n",
    "print(alpha_only(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
