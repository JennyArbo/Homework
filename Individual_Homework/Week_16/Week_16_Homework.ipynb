{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 16 Homework: SVMs, over, and under sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all of the usual suspects before I get started on the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "#Scikit-learn modules, collections, and imblearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the 2 datasets we will use this week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2   3   4   5      6   7   8   9   10  11   12    13  14\n",
       "0   1  22.08  11.46   2   4   4  1.585   0   0   0   1   2  100  1213   0\n",
       "1   0  22.67   7.00   2   8   4  0.165   0   0   0   0   2  160     1   0\n",
       "2   0  29.58   1.75   1   4   4  1.250   0   0   0   1   2  280     1   0\n",
       "3   0  21.67  11.50   1   5   3  0.000   1   1  11   1   2    0     1   1\n",
       "4   1  20.17   8.17   2   6   4  1.960   1   1  14   0   2   60   159   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df = pd.read_table(\"australian.dat\", sep=\" \", header = None)\n",
    "credit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Perform combined over and undersampling on the diabetes dataset (use SMOTEENN). Explain how combined sampling works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for SMOTEENN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test, train, split and using a standard scaler to standardize data\n",
    "\n",
    "#Setting X and y values\n",
    "X = diabetes_df.drop('Outcome',axis = 1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "#Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "#Standardize\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy score (SMOTEEN): 0.7088888888888889\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.84      0.64      0.78      0.73      0.71      0.49       100\n",
      "          1       0.54      0.78      0.64      0.64      0.71      0.50        54\n",
      "\n",
      "avg / total       0.74      0.69      0.73      0.70      0.71      0.50       154\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN \n",
    "sm = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train_scaler, y_train)\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_scaler)\n",
    "\n",
    "bal_acc_SMOTEENN = balanced_accuracy_score(y_test, y_pred)\n",
    "print('balanced accuracy score (SMOTEEN):', bal_acc_SMOTEENN)\n",
    "\n",
    "cf_matrix_smoteenn = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix_smoteenn, annot=True)\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTEENN descriptions:**\n",
    "\n",
    "SMOTEEN stands for synthetic minority oversampling technique-edited nearest neighbors. It combines the minority oversampling from SMOTE where a random example from the minority class is chosen along with a random nearest neighbor. The synthetic data point is selected randomly on a line between the minority example and the nearest neighbor point then is added to the minority dataset. This can be repeated until the desired representation of the minority class is reached. The ENN part of SMOTEENN describes the process by which misclassified data points are selected for removal. Points can be removed from the majority, minority, or any/all classes by selecting those parameters when defining SMOTEENN in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Comment on the performance of combined sampling vs the other approaches we have used for the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of techniques:**\n",
    "\n",
    "Based on the logistic regression, logistic regression with SMOTE, and logistic regression with SMOTEENN, it appears that the precision is slightly higher for SMOTEENN than SMOTE but the recall is a tiny bit higher for SMOTE. Both resampling techniques improve model performance. \n",
    "\n",
    "I do womder if performing additional preprocessing could be helpful. I will rerun recursive feature analysis to see if feature selection can help improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) What is outlier detection? Why is it useful? What methods can you use for outlier detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are data (either single or multiple points) which do not fit the general trend or pattern of the rest of the dataset. Generally, outliers can be the result of error (human, machine, experimental, sampling, processing, etc), can be included intentionally to test limits of the model, or can represent a true value of the data (called a novelty). The origin of the outlier can also have implications for how it is treated. For instance, in climate (and in particular, in temperature) data, there have been many cases where we see the entire data distribution shifting as our climate changes in response to human influences, leading in some cases to significant outliers that are based on true values and should be included as possibilities in models.\n",
    "\n",
    "Outliers have the potential to significantly impact a model's performance. As a result, we need to have an understanding of outliers, the underlying causes of those outliers, how to detect them, and how to handle them. The process of outlier detection allows separation of the dataset into outliers and non-outliers. This is useful for many reasons. We can use these classifications to exclude data (for instance, if we know it is due to error), include (if we know it is a novelty and an actual observation/occurence), or to tag samples that may be suspicious (we could for instance look at model output and performance with and without these points). Outliers sometimes can unveil sources of error that should be addressed and other times can help uncover very interesting and important features. \n",
    "\n",
    "There are several different methods that we can use for outlier detection.\n",
    "\n",
    "First, outliers can be univariate (found in a single feature space) or multivariate (found in multi-feature space). This is important to understand so we can consider how many features are considered and how.\n",
    "\n",
    "Ideally, we would also understand something about the data distribution and the distribution of our outliers.\n",
    "\n",
    "The z-score is a common method of outlier detection (parametric distribution). The z-score assumes a gaussian data distribution and indicates how many standard deviations the value of a given point is away from the mean. A threshold (often 2.5-3.5 standard deviations from the mean) can be selected and used to separate the values in the dataset into outliers and non-outliers. While there are other methods that can be used for parametric distributions, the z-score is the simplest and most widely used. Scipy and sci-kit learn have functions to calculate z-score.\n",
    "\n",
    "Dbscan (density based spatial clustering of applications with noise) is a non-parametric method of outlier detection. This technique identifies neighbors based on density clustering of data points within defined limits/distances in feature space. Points outside of the density cluster are considered outliers. Sci-kit learn has a Dbscan function. This is an unsupervised learning method and it will determine based on the data how many clusters exist. Data deemed outliers are given a designation of -1. These data points may sometimes be considered noise and with the -1 designation may be easily removed or studied.\n",
    "\n",
    "Another example of outlier detection is isolated forest (also a non-parametric method and unsupervised learning technique). There is a built in module within sci-kit learn to use an isolated forest for outlier detection. This algorithm works well for large datasets and is relatively simple computationally, which leads to more reasonable computation times. This technique is based on the idea of a decision tree. Anomalous data (which will be labeled as outliers) have shorter paths compared to \"normal\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Perform a linear SVM to predict credit approval (last column) using this dataset: https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29 . \n",
    "### Make sure you look at the accompanying document that describes the data in the dat file. You will need to either convert this data to another file type or import the dat file to python. \n",
    "\n",
    "\n",
    "#### You can use this code, but otherwise you follow standard practices we have already used many times: \n",
    "#### from sklearn.svm import SVC\n",
    "#### classifier = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the SVC module from scikit-learn\n",
    "from sklearn.svm import SVC \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN values: The documentation indicates that there were missing values initially but these have been replaced by the mode for categorical values and the mean for continuous values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train, test datasets and standardizing the data using a standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1       2   3   4   5      6   7   8   9   10  11   12    13\n",
      "0     1  22.08  11.460   2   4   4  1.585   0   0   0   1   2  100  1213\n",
      "1     0  22.67   7.000   2   8   4  0.165   0   0   0   0   2  160     1\n",
      "2     0  29.58   1.750   1   4   4  1.250   0   0   0   1   2  280     1\n",
      "3     0  21.67  11.500   1   5   3  0.000   1   1  11   1   2    0     1\n",
      "4     1  20.17   8.170   2   6   4  1.960   1   1  14   0   2   60   159\n",
      "..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ..  ..  ..  ...   ...\n",
      "685   1  31.57  10.500   2  14   4  6.500   1   0   0   0   2    0     1\n",
      "686   1  20.67   0.415   2   8   4  0.125   0   0   0   0   2    0    45\n",
      "687   0  18.83   9.540   2   6   4  0.085   1   0   0   0   2  100     1\n",
      "688   0  27.42  14.500   2  14   8  3.085   1   1   1   0   2  120    12\n",
      "689   1  41.00   0.040   2  10   4  0.040   0   1   1   0   1  560     1\n",
      "\n",
      "[690 rows x 14 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "685    1\n",
      "686    0\n",
      "687    1\n",
      "688    1\n",
      "689    1\n",
      "Name: 14, Length: 690, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Test, train, split and using a standard scaler to standardize data\n",
    "\n",
    "#Setting X and y values\n",
    "X_c = credit_df.drop([14],axis = 1)\n",
    "y_c = credit_df[14]\n",
    "print(X_c)\n",
    "print(y_c)\n",
    "credit_df\n",
    "X_c\n",
    "\n",
    "#Train, test, split\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size = 0.2, random_state = 42, stratify = y_c)\n",
    "#print(X_train_c)\n",
    "#print(X_test_c)\n",
    "#print(y_train_c)\n",
    "#print(y_test_c)\n",
    "\n",
    "#Standardize\n",
    "#sc = StandardScaler()\n",
    "#X_train_scaler = sc.fit_transform(X_train)\n",
    "#X_test_scaler = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score: 0.7898550724637681\n"
     ]
    }
   ],
   "source": [
    "#setting the classifier to be a linear SVC\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_train_c, y_train_c)\n",
    "y_pred_c =classifier.predict(X_test_c)\n",
    "print(\"SVC score:\", classifier.score(X_test_c, y_test_c))\n",
    "#print(classifier.score(X_test_c,y_test_c))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#y_pred_s = model_s.predict(X_test_scalers)\n",
    "\n",
    "#bal_acc_SVC = balanced_accuracy_score(y_test_c, y_pred_c)\n",
    "#print('balanced accuracy score (SMOTE):', bal_acc_SMOTE)\n",
    "\n",
    "#cf_matrix_smote = confusion_matrix(y_tests, y_pred_s)\n",
    "\n",
    "#cf_matrix_naive = confusion_matrix(y_test, y_pred)\n",
    "#sns.heatmap(cf_matrix_smote, annot=True)\n",
    "\n",
    "#print(classification_report_imbalanced(y_tests, y_pred_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) How did the SVM model perform? Use a classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV average score: 0.84\n"
     ]
    }
   ],
   "source": [
    "#Code:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Checking cross validation score\n",
    "cv_scores = cross_val_score(classifier, X_train_c, y_train_c, cv=10)\n",
    "print(\"CV average score: %.2f\" % cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54 23]\n",
      " [ 6 55]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_pred = classifier.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_c, y_pred_c)\n",
    "print(conf_matrix)\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.70      0.79        77\n",
      "           1       0.71      0.90      0.79        61\n",
      "\n",
      "    accuracy                           0.79       138\n",
      "   macro avg       0.80      0.80      0.79       138\n",
      "weighted avg       0.81      0.79      0.79       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "\n",
    "c_r = classification_report(y_test_c, y_pred_c)\n",
    "print(c_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "Overall, the linear SVC performed fairly well without adjusting the hyperparameters or doing much in the way of preprocessing the data. The recall, precision, and accuracy scores are all around 0.8. From the confusion matrix and classification report, we can see that the precision for class 1 is quite a bit lower but the recall for class 0 is pretty low. In terms of credit approval rating, the recall for credit denial is poor in comparison to credit approval. So, more people are misclassified in terms of not receiving approval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) What kinds of jobs in data are you most interested in? Do some research on what is out there. Write about your thoughts in under 400 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recently learned about Earth analytics. Essentially, Earth analytics merges the study of Earth Science with data science/analytics. The focus is on the use of data driven approaches to understand, evaluate, and provide solutions for Earth and environmental science processes and issues. Ideally, I would love to work in this field. In particular, I am really passionate about using data driven techniques to advance science and find creative solutions to problems at the interface between humans and our environment. I would really love to find a job in this field because it would explicitly use my expertise from my Ph.D. and postdoctoral research. I still have a huge passion for science and it would be unbelievable to combine my love for science, society, and data in a career. \n",
    "\n",
    "With that said, I don’t want to back myself into too much of a corner. So while I would love to work in Earth analytics, I could also see myself being content in other roles. I would love to find ways to stay connected to broadly science related industries. I could see myself being happy in a data science role. I really enjoy digging into complex and societally important problems, thinking about things in new and creative ways. I enjoy finding ways to take complex datasets and concepts and turn them into products and visuals that enable me to communicate those complex subjects clearly to audiences of subject matter experts and laypeople alike. Additionally, I really enjoy data visualization (although I have a LOT left to learn on that end). Related to the previous two points, I love being able to tell a story with data and visualizations and would really enjoy a job that allows me to do that. \n",
    "\n",
    "This class has also been really helpful in understanding some of the topics I’m not as excited about. I enjoyed learning about databases and their organization, but I would prefer not to be the person building them. I’m much more interested in the analysis, presentation, and visualization of data rather than designing and implementing the underlying data structures. I would be happy to do it as part of a larger project, but I would really want those higher level problem solving skills and communication skills to be part of my projects as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
